{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJbBsN5rgTekyAX7z6cHph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josejailson/TFServing/blob/main/serving_a_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEsva7CKsQW7"
      },
      "outputs": [],
      "source": [
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH2z4284sHs-"
      },
      "source": [
        "# Serving a TensorFlow Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abl6NxTfsHs-"
      },
      "source": [
        "Let's start by deploying a model using TF Serving, then we'll deploy to Google Vertex AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymYXZVyrsHs-"
      },
      "source": [
        "## Using TensorFlow Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njUudWxasHs_"
      },
      "source": [
        "The first thing we need to do is to build and train a model, and export it to the SavedModel format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAuQEGfrsHs_"
      },
      "source": [
        "### Exporting SavedModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU2z0UgEsHs_"
      },
      "source": [
        "Let's load the MNIST dataset, scale it, and split it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQSaENatsHs_",
        "outputId": "1c81909a-7c3a-400e-a1d4-88c66d8dfde1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 16s 8ms/step - loss: 0.6799 - accuracy: 0.8245 - val_loss: 0.3726 - val_accuracy: 0.9026\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3542 - accuracy: 0.9018 - val_loss: 0.3029 - val_accuracy: 0.9148\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3062 - accuracy: 0.9140 - val_loss: 0.2692 - val_accuracy: 0.9244\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2771 - accuracy: 0.9224 - val_loss: 0.2482 - val_accuracy: 0.9306\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2550 - accuracy: 0.9287 - val_loss: 0.2294 - val_accuracy: 0.9378\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2367 - accuracy: 0.9335 - val_loss: 0.2157 - val_accuracy: 0.9418\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2211 - accuracy: 0.9389 - val_loss: 0.2010 - val_accuracy: 0.9462\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2076 - accuracy: 0.9421 - val_loss: 0.1921 - val_accuracy: 0.9494\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1955 - accuracy: 0.9461 - val_loss: 0.1816 - val_accuracy: 0.9526\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1852 - accuracy: 0.9487 - val_loss: 0.1721 - val_accuracy: 0.9544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "# extra code – load and split the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# extra code – build & train an MNIST model (also handles image preprocessing)\n",
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "model_name = \"my_mnist_model\"\n",
        "model_version = \"0001\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPilJJIOsHtA"
      },
      "source": [
        "Let's take a look at the file tree (we've discussed what each of these file is used for in chapter 10):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0E6sq-vsHtA",
        "outputId": "4f964867-37e3-495b-d940-424b0d0cac49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my_mnist_model/0001',\n",
              " 'my_mnist_model/0001/assets',\n",
              " 'my_mnist_model/0001/fingerprint.pb',\n",
              " 'my_mnist_model/0001/keras_metadata.pb',\n",
              " 'my_mnist_model/0001/saved_model.pb',\n",
              " 'my_mnist_model/0001/variables',\n",
              " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0001/variables/variables.index']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "sorted([str(path) for path in model_path.parent.glob(\"**/*\")])  # extra code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjgmowm9sHtE"
      },
      "source": [
        "Let's inspect the SavedModel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RzQjFQOsHtF",
        "outputId": "84f1debd-068d-4d84-eacc-7398bb284cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel contains the following tag-sets:\n",
            "'serve'\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir '{model_path}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cvnNivusHtF",
        "outputId": "1243e145-0307-4518-9992-abca01c4298e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir '{model_path}' --tag_set serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQwRaZXasHtF",
        "outputId": "e4e32bea-703e-40aa-bf3b-1d0f701e46d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['flatten_input'] tensor_info:\n",
            "      dtype: DT_UINT8\n",
            "      shape: (-1, 28, 28)\n",
            "      name: serving_default_flatten_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense_1'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir '{model_path}' --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B39Db0fsHtG"
      },
      "source": [
        "For even more details, you can run the following command:\n",
        "\n",
        "```ipython\n",
        "!saved_model_cli show --dir '{model_path}' --all\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho_7hDuYsHtH"
      },
      "source": [
        "### Installing and Starting TensorFlow Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51jGVZWwsHtH"
      },
      "source": [
        "If you are running this notebook in Colab or Kaggle, TensorFlow Server needs to be installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8m0YG5NsHtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660463b3-f0b0-4666-971f-402b270ae512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0   3012      0 --:--:-- --:--:-- --:--:--  3012\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:7 https://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:9 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [348 B]\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,776 kB]\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:13 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [338 B]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,354 kB]\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,255 kB]\n",
            "Fetched 7,728 kB in 4s (2,149 kB/s)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.12.1 [430 MB]\n",
            "Fetched 430 MB in 18s (23.3 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 122541 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.12.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.12.1) ...\n",
            "Setting up tensorflow-model-server (2.12.1) ...\n"
          ]
        }
      ],
      "source": [
        "if \"google.colab\" in sys.modules or \"kaggle_secrets\" in sys.modules:\n",
        "    url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n",
        "    src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n",
        "    !echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
        "    !apt update -q && apt-get install -y tensorflow-model-server\n",
        "    %pip install -q -U tensorflow-serving-api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HdTsUpMsHtI"
      },
      "source": [
        "If `tensorflow_model_server` is installed (e.g., if you are running this notebook in Colab), then the following 2 cells will start the server. If your OS is Windows, you may need to run the `tensorflow_model_server` command in a terminal, and replace `${MODEL_DIR}` with the full path to the `my_mnist_model` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb9FNZCrsHtI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CyAvdECsHtI"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "tensorflow_model_server \\\n",
        "    --port=8500 \\\n",
        "    --rest_api_port=8501 \\\n",
        "    --model_name=my_mnist_model \\\n",
        "    --model_base_path=\"${MODEL_DIR}\" >my_server.log 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFFcaCj7sHtI"
      },
      "source": [
        "If you are running this notebook on your own machine, and you prefer to install TF Serving using Docker, first make sure [Docker](https://docs.docker.com/install/) is installed, then run the following commands in a terminal. You must replace `/path/to/my_mnist_model` with the appropriate absolute path to the `my_mnist_model` directory, but do not modify the container path `/models/my_mnist_model`.\n",
        "\n",
        "```bash\n",
        "docker pull tensorflow/serving  # downloads the latest TF Serving image\n",
        "\n",
        "docker run -it --rm -v \"/path/to/my_mnist_model:/models/my_mnist_model\" \\\n",
        "    -p 8500:8500 -p 8501:8501 -e MODEL_NAME=my_mnist_model tensorflow/serving\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiHiF4_QsHtI"
      },
      "source": [
        "### Querying TF Serving through the REST API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdqVmF-OsHtJ"
      },
      "source": [
        "Next, let's send a REST query to TF Serving:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4VNAQKUsHtJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "X_new = X_test[:3]  # pretend we have 3 new digit images to classify\n",
        "request_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V4KgCrMsHtJ",
        "outputId": "0ddd4c06-d9bf-4261-db74-5b4b20ca29c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"signature_name\": \"serving_default\", \"instances\": [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0..., 0, 0]]]}'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "request_json[:100] + \"...\" + request_json[-10:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2oof5SgsHtJ"
      },
      "source": [
        "Now let's use TensorFlow Serving's REST API to make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxSdZPgTsHtJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status()  # raise an exception in case of error\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHxKC6_fsHtT",
        "outputId": "358ed07c-1c81-4f01-bb57-be853d5fc9a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxawwhKDsHtU"
      },
      "source": [
        "### Querying TF Serving through the gRPC API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhBnAhaisHtU"
      },
      "outputs": [],
      "source": [
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_spec.signature_name = \"serving_default\"\n",
        "input_name = model.input_names[0]  # == \"flatten_input\"\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chvk28mLsHtU"
      },
      "outputs": [],
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2E6x8JPsHtV"
      },
      "source": [
        "Convert the response to a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3bpdkKSmsHtV"
      },
      "outputs": [],
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hK5btEgsHtV",
        "outputId": "ab140ff8-5cf9-4006-b372-0642732d9a67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkafaRqJsHtV"
      },
      "source": [
        "If your client does not include the TensorFlow library, you can convert the response to a NumPy array like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv7K91LYsHtV",
        "outputId": "b1d21886-29bd-48b5-e605-4a3a02b1e4db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# extra code – shows how to avoid using tf.make_ndarray()\n",
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
        "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9GdCsn2sHtW"
      },
      "source": [
        "### Deploying a new model version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Nfb0OAnnsHtW",
        "outputId": "59128b77-987e-42b3-ea10-218f18c2defb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 2s 931us/step - loss: 0.7039 - accuracy: 0.8056 - val_loss: 0.3418 - val_accuracy: 0.9042\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 1s 855us/step - loss: 0.3204 - accuracy: 0.9082 - val_loss: 0.2674 - val_accuracy: 0.9242\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 2s 883us/step - loss: 0.2650 - accuracy: 0.9235 - val_loss: 0.2227 - val_accuracy: 0.9368\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 1s 869us/step - loss: 0.2319 - accuracy: 0.9329 - val_loss: 0.2032 - val_accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 1s 870us/step - loss: 0.2089 - accuracy: 0.9399 - val_loss: 0.1833 - val_accuracy: 0.9482\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 1s 871us/step - loss: 0.1908 - accuracy: 0.9446 - val_loss: 0.1740 - val_accuracy: 0.9498\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 2s 873us/step - loss: 0.1756 - accuracy: 0.9490 - val_loss: 0.1605 - val_accuracy: 0.9540\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 2s 877us/step - loss: 0.1631 - accuracy: 0.9524 - val_loss: 0.1543 - val_accuracy: 0.9558\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 2s 879us/step - loss: 0.1517 - accuracy: 0.9567 - val_loss: 0.1460 - val_accuracy: 0.9570\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 1s 872us/step - loss: 0.1429 - accuracy: 0.9584 - val_loss: 0.1358 - val_accuracy: 0.9618\n"
          ]
        }
      ],
      "source": [
        "# extra code – build and train a new MNIST model version\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZUYg__7sHtW",
        "outputId": "5115c5cb-c13e-4e53-9660-86bd409ad067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
          ]
        }
      ],
      "source": [
        "model_version = \"0002\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxiI_qcJsHtX"
      },
      "source": [
        "Let's take a look at the file tree again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtVscFrYsHtX",
        "outputId": "b88a06bb-eefc-4606-d338-864c908fab83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['my_mnist_model/0001',\n",
              " 'my_mnist_model/0001/assets',\n",
              " 'my_mnist_model/0001/keras_metadata.pb',\n",
              " 'my_mnist_model/0001/saved_model.pb',\n",
              " 'my_mnist_model/0001/variables',\n",
              " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0001/variables/variables.index',\n",
              " 'my_mnist_model/0002',\n",
              " 'my_mnist_model/0002/assets',\n",
              " 'my_mnist_model/0002/keras_metadata.pb',\n",
              " 'my_mnist_model/0002/saved_model.pb',\n",
              " 'my_mnist_model/0002/variables',\n",
              " 'my_mnist_model/0002/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0002/variables/variables.index']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted([str(path) for path in model_path.parent.glob(\"**/*\")])  # extra code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHVRnTTmsHtX"
      },
      "source": [
        "**Warning**: You may need to wait a minute before the new model is loaded by TensorFlow Serving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fA6QBIwsHtY"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9iiy5U0sHtY",
        "outputId": "fff290fc-d8b3-42cd-afbd-00656c5bd60a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSfEyAiasHtZ",
        "outputId": "e0e0738b-20ff-4e37-962a-018535e2e74e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6BhDtJcsHtZ"
      },
      "source": [
        "## Creating a Prediction Service on Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL90pQG_sHta"
      },
      "source": [
        "Follow the instructions in the book to create a Google Cloud Platform account and activate the Vertex AI and Cloud Storage APIs. Then, if you're running this notebook in Colab, you can run the following cell to authenticate using the same Google account as you used with Google Cloud Platform, and authorize this Colab to access your data.\n",
        "\n",
        "**WARNING: only do this if you trust this notebook!**\n",
        "* Be extra careful if this is not the official notebook from https://github.com/ageron/handson-ml3: the Colab URL should start with https://colab.research.google.com/github/ageron/handson-ml3. Or else, the code could do whatever it wants with your data.\n",
        "\n",
        "If you are not running this notebook in Colab, you must follow the instructions in the book to create a service account and generate a key for it, download it to this notebook's directory, and name it `my_service_account_key.json` (or make sure the `GOOGLE_APPLICATION_CREDENTIALS` environment variable points to your key)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lF55QmKsHta"
      },
      "outputs": [],
      "source": [
        "project_id = \"my_project\"  ##### CHANGE THIS TO YOUR PROJECT ID #####\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "elif \"kaggle_secrets\" in sys.modules:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    UserSecretsClient().set_gcloud_credentials(project=project_id)\n",
        "else:\n",
        "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_service_account_key.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOKNaEpmsHta"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "bucket_name = \"my_bucket\"  ##### CHANGE THIS TO A UNIQUE BUCKET NAME #####\n",
        "location = \"us-central1\"\n",
        "\n",
        "storage_client = storage.Client(project=project_id)\n",
        "bucket = storage_client.create_bucket(bucket_name, location=location)\n",
        "#bucket = storage_client.bucket(bucket_name)  # to reuse a bucket instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh1i1p2fsHtb"
      },
      "outputs": [],
      "source": [
        "def upload_directory(bucket, dirpath):\n",
        "    dirpath = Path(dirpath)\n",
        "    for filepath in dirpath.glob(\"**/*\"):\n",
        "        if filepath.is_file():\n",
        "            blob = bucket.blob(filepath.relative_to(dirpath.parent).as_posix())\n",
        "            blob.upload_from_filename(filepath)\n",
        "\n",
        "upload_directory(bucket, \"my_mnist_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quOqiz43sHtc"
      },
      "outputs": [],
      "source": [
        "# extra code – a much faster multithreaded implementation of upload_directory()\n",
        "#              which also accepts a prefix for the target path, and prints stuff\n",
        "\n",
        "from concurrent import futures\n",
        "\n",
        "def upload_file(bucket, filepath, blob_path):\n",
        "    blob = bucket.blob(blob_path)\n",
        "    blob.upload_from_filename(filepath)\n",
        "\n",
        "def upload_directory(bucket, dirpath, prefix=None, max_workers=50):\n",
        "    dirpath = Path(dirpath)\n",
        "    prefix = prefix or dirpath.name\n",
        "    with futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_filepath = {\n",
        "            executor.submit(\n",
        "                upload_file,\n",
        "                bucket, filepath,\n",
        "                f\"{prefix}/{filepath.relative_to(dirpath).as_posix()}\"\n",
        "            ): filepath\n",
        "            for filepath in sorted(dirpath.glob(\"**/*\"))\n",
        "            if filepath.is_file()\n",
        "        }\n",
        "        for future in futures.as_completed(future_to_filepath):\n",
        "            filepath = future_to_filepath[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "            except Exception as ex:\n",
        "                print(f\"Error uploading {filepath!s:60}: {ex}\")  # f!s is str(f)\n",
        "            else:\n",
        "                print(f\"Uploaded {filepath!s:60}\", end=\"\\r\")\n",
        "\n",
        "    print(f\"Uploaded {dirpath!s:60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DySS563esHtc"
      },
      "source": [
        "Alternatively, if you installed Google Cloud CLI (it's preinstalled on Colab), then you can use the following `gsutil` command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AjVprXgsHtd"
      },
      "outputs": [],
      "source": [
        "#!gsutil -m cp -r my_mnist_model gs://{bucket_name}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKYfsivbsHtd",
        "outputId": "4552c1dd-5b15-450d-b75f-5d13c3c05dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Model\n",
            "Create Model backing LRO: projects/522977795627/locations/us-central1/models/4798114811986575360/operations/53403898236370944\n",
            "Model created. Resource name: projects/522977795627/locations/us-central1/models/4798114811986575360\n",
            "To use this Model in another session:\n",
            "model = aiplatform.Model('projects/522977795627/locations/us-central1/models/4798114811986575360')\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "server_image = \"gcr.io/cloud-aiplatform/prediction/tf2-gpu.2-8:latest\"\n",
        "\n",
        "aiplatform.init(project=project_id, location=location)\n",
        "mnist_model = aiplatform.Model.upload(\n",
        "    display_name=\"mnist\",\n",
        "    artifact_uri=f\"gs://{bucket_name}/my_mnist_model/0001\",\n",
        "    serving_container_image_uri=server_image,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnz1XnaRsHtd"
      },
      "source": [
        "**Warning**: this cell may take several minutes to run, as it waits for Vertex AI to provision the compute nodes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBwVWJWgsHte",
        "outputId": "79c7c332-7cf8-4a93-f17a-1752abd1d655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Endpoint\n",
            "Create Endpoint backing LRO: projects/522977795627/locations/us-central1/endpoints/5133373499481522176/operations/4135354010494304256\n",
            "Endpoint created. Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "To use this Endpoint in another session:\n",
            "endpoint = aiplatform.Endpoint('projects/522977795627/locations/us-central1/endpoints/5133373499481522176')\n",
            "Deploying Model projects/522977795627/locations/us-central1/models/4798114811986575360 to Endpoint : projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Deploy Endpoint model backing LRO: projects/522977795627/locations/us-central1/endpoints/5133373499481522176/operations/388359120522051584\n",
            "Endpoint model deployed. Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n"
          ]
        }
      ],
      "source": [
        "endpoint = aiplatform.Endpoint.create(display_name=\"mnist-endpoint\")\n",
        "\n",
        "endpoint.deploy(\n",
        "    mnist_model,\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=5,\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO5P_SONsHte"
      },
      "outputs": [],
      "source": [
        "response = endpoint.predict(instances=X_new.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TTVNgCLsHtf",
        "outputId": "78406832-f314-48e2-cb07-0d3d6146fc16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.round(response.predictions, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er1OvtQBsHtf",
        "outputId": "8bbed69f-5e46-4696-ffc7-e50956c701ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Undeploying Endpoint model: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Undeploy Endpoint model backing LRO: projects/522977795627/locations/us-central1/endpoints/5133373499481522176/operations/3579722406467469312\n",
            "Endpoint model undeployed. Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Deleting Endpoint : projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Delete Endpoint  backing LRO: projects/522977795627/locations/us-central1/operations/4738836360561950720\n",
            "Endpoint deleted. . Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n"
          ]
        }
      ],
      "source": [
        "endpoint.undeploy_all()  # undeploy all models from the endpoint\n",
        "endpoint.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtKVSY80sHtf"
      },
      "source": [
        "## Running Batch Prediction Jobs on Vertex AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHHIxReysHtg",
        "outputId": "340dddce-d0ac-45e2-bea9-5ace8a96d019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded my_mnist_batch                                              \n"
          ]
        }
      ],
      "source": [
        "batch_path = Path(\"my_mnist_batch\")\n",
        "batch_path.mkdir(exist_ok=True)\n",
        "with open(batch_path / \"my_mnist_batch.jsonl\", \"w\") as jsonl_file:\n",
        "    for image in X_test[:100].tolist():\n",
        "        jsonl_file.write(json.dumps(image))\n",
        "        jsonl_file.write(\"\\n\")\n",
        "\n",
        "upload_directory(bucket, batch_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AfCCHY7sHtg",
        "outputId": "d27e3dd7-3254-458c-91a4-774da8e5923e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating BatchPredictionJob\n",
            "BatchPredictionJob created. Resource name: projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n",
            "To use this BatchPredictionJob in another session:\n",
            "bpj = aiplatform.BatchPredictionJob('projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544')\n",
            "View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/4346926367237996544?project=522977795627\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_PENDING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_SUCCEEDED\n",
            "BatchPredictionJob run completed. Resource name: projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n"
          ]
        }
      ],
      "source": [
        "batch_prediction_job = mnist_model.batch_predict(\n",
        "    job_display_name=\"my_batch_prediction_job\",\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    starting_replica_count=1,\n",
        "    max_replica_count=5,\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=1,\n",
        "    gcs_source=[f\"gs://{bucket_name}/{batch_path.name}/my_mnist_batch.jsonl\"],\n",
        "    gcs_destination_prefix=f\"gs://{bucket_name}/my_mnist_predictions/\",\n",
        "    sync=True  # set to False if you don't want to wait for completion\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7QOEC41sHtg",
        "outputId": "cc0ea8de-457b-48de-e462-a161a8e8be13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gcs_output_directory: \"gs://my_bucket/my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_prediction_job.output_info  # extra code – shows the output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmkos7dqsHth",
        "outputId": "a6ffcd21-36fc-4e96-af77-8f7174f8d4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z/prediction.errors_stats-00000-of-00001\n",
            "my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z/prediction.results-00000-of-00002\n",
            "my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z/prediction.results-00001-of-00002\n"
          ]
        }
      ],
      "source": [
        "y_probas = []\n",
        "for blob in batch_prediction_job.iter_outputs():\n",
        "    print(blob.name)  # extra code\n",
        "    if \"prediction.results\" in blob.name:\n",
        "        for line in blob.download_as_text().splitlines():\n",
        "            y_proba = json.loads(line)[\"prediction\"]\n",
        "            y_probas.append(y_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liWNC6MZsHth"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_probas, axis=1)\n",
        "accuracy = np.sum(y_pred == y_test[:100]) / 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XHe18C-sHth",
        "outputId": "f49bc26a-491d-4d74-d0dd-01607f506014"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBKJs43XsHth",
        "outputId": "733d5ae4-39e6-4476-f8a1-3ba294608e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting Model : projects/522977795627/locations/us-central1/models/4798114811986575360\n",
            "Delete Model  backing LRO: projects/522977795627/locations/us-central1/operations/598902403101622272\n",
            "Model deleted. . Resource name: projects/522977795627/locations/us-central1/models/4798114811986575360\n"
          ]
        }
      ],
      "source": [
        "mnist_model.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNxBwyyxsHti"
      },
      "source": [
        "Let's delete all the directories we created on GCS (i.e., all the blobs with these prefixes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94dYTcB5sHti",
        "outputId": "e173eff7-ac2e-4aeb-9c10-e0ba72368469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting BatchPredictionJob : projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n",
            "Delete BatchPredictionJob  backing LRO: projects/522977795627/locations/us-central1/operations/6699028098374959104\n",
            "BatchPredictionJob deleted. . Resource name: projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n"
          ]
        }
      ],
      "source": [
        "for prefix in [\"my_mnist_model/\", \"my_mnist_batch/\", \"my_mnist_predictions/\"]:\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "    for blob in blobs:\n",
        "        blob.delete()\n",
        "\n",
        "#bucket.delete()  # uncomment and run if you want to delete the bucket itself\n",
        "batch_prediction_job.delete()"
      ]
    }
  ]
}